{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "model = Ollama(model='gemma2:2b', stop=[\"<|eot_id|>\"]) # Added the stop token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = input()\n",
    "user_prompt = f\"{text}\"\n",
    "\n",
    "system_prompt = \"\"\"Think and write your step-by-step reasoning before responding. \n",
    "Please write one word in English that corresponds to the following user's question, fully spelled out and without abbreviations. \n",
    "For example, respond to 'RAG' with 'Retrieval-Augmented Generation' and to 'CNN' with 'Convolutional Neural Network'.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    <|begin_of_text|>\n",
    "    <|start_header_id|>system<|end_header_id|>\n",
    "    {system_prompt}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>user<|end_header_id|>\n",
    "    {user_prompt}\n",
    "    <|eot_id|>\n",
    "    <|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=['system_prompt', 'user_prompt'],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_word = model(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donald'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/wiki/Donald'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"https://en.wikipedia.org/wiki/{key_word.strip()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(f\"https://en.wikipedia.org/wiki/{key_word.strip()}\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0) \n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n",
    "# docs = vectorstore.similarity_search(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = f\"{user_prompt} on detail.\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "Please write all conversations in Korean(ÌïúÍµ≠Ïñ¥).\n",
    "Think and write your step-by-step reasoning before responding.\n",
    "Write the article title using # in Markdown syntax.\n",
    "The character limit is 200 characters.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qachain = RetrievalQA.from_chain_type(model, retriever=vectorstore.as_retriever())\n",
    "\n",
    "response = qachain(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '\\n    <|begin_of_text|>\\n    <|start_header_id|>system<|end_header_id|>\\n    \\nPlease write all conversations in Korean(ÌïúÍµ≠Ïñ¥).\\nThink and write your step-by-step reasoning before responding.\\nWrite the article title using # in Markdown syntax.\\nThe character limit is 200 characters.\\n\\n    <|eot_id|>\\n    <|start_header_id|>user<|end_header_id|>\\n    Ìä∏ÎüºÌîÑÏóê ÎåÄÌï¥ÏÑú ÏÑ§Î™ÖÌï¥Ï§ò by korean.\\n    <|eot_id|>\\n    <|start_header_id|>assistant<|end_header_id|>\\n',\n",
       " 'result': '## #Donald  (Don) \\n\\nLet\\'s break down why \"Donald\" is so prominent, but we need to start with context!\\n\\n\\n* **What\\'s the question?** We don\\'t have a specific question about Donald. So let me offer some points to consider in answering your questions.\\n   \\n    * Do you want to know about how often this name appears? \\n    * Are you curious about why it is used so commonly, or what its cultural significance is?\\n\\nPlease provide more information on the question you\\'d like to answer! üòÑ  \\n\\n\\n\\n'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## #Donald  (Don) \n",
      "\n",
      "Let's break down why \"Donald\" is so prominent, but we need to start with context!\n",
      "\n",
      "\n",
      "* **What's the question?** We don't have a specific question about Donald. So let me offer some points to consider in answering your questions.\n",
      "   \n",
      "    * Do you want to know about how often this name appears? \n",
      "    * Are you curious about why it is used so commonly, or what its cultural significance is?\n",
      "\n",
      "Please provide more information on the question you'd like to answer! üòÑ  \n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
